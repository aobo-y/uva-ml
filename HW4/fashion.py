# -*- coding: utf-8 -*-
"""fashion_template.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WNSpCNSEtWkBuMl6XvGQeHTrY9BNOnBn

Upload the fashion_train.csv file to your google drive and specify the correct path in the main method. When prompted, provide the authorization key.
"""

# Machine Learning Homework 4 - Image Classification

__author__ = '**'

# General imports
import numpy as np
import matplotlib.pyplot as plt
from sklearn.utils import shuffle
from sklearn.model_selection import GridSearchCV
import os
import sys
import pandas as pd

# Keras
import keras
from keras.models import Sequential
from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten
from keras.wrappers.scikit_learn import KerasClassifier

# Google Colab stuff
# from google.colab import drive
# drive.mount('/content/drive')

"""The below methods have been provided for you."""

### Already implemented
def get_data(datafile):
  dataframe = pd.read_csv(datafile)
  dataframe = shuffle(dataframe)
  data = list(dataframe.values)
  labels, images = [], []
  for line in data:
    labels.append(line[0])
    images.append(line[1:])
  labels = np.array(labels)
  images = np.array(images).astype('float32')
  images /= 255
  return images, labels


### Already implemented
def visualize_weights(trained_model, num_to_display=20, save=True, hot=True):
  layer1 = trained_model.layers[0]
  weights = layer1.get_weights()[0]

  # Feel free to change the color scheme
  colors = 'hot' if hot else 'binary'

  for i in range(num_to_display):
    wi = weights[:,i].reshape(28, 28)
    plt.imshow(wi, cmap=colors, interpolation='nearest')
    plt.show()


### Already implemented
def output_predictions(predictions):
  with open('predictions.txt', 'w+') as f:
    for pred in predictions:
      f.write(str(pred) + '\n')

"""Implement the following method to generate plots of the train and validation accuracy and loss vs epochs.
You should call this method for your best-performing MLP model and best-performing CNN model
(4 plots total--2 accuracy plots, 2 loss plots).
"""

def plot_history(history):
  train_loss_history = history.history['loss']
  val_loss_history = history.history['val_loss']

  train_acc_history = history.history['acc']
  val_acc_history = history.history['val_acc']

  # plot

  # Plot training & validation loss values
  plt.plot(train_loss_history)
  plt.plot(val_loss_history)
  plt.title('Model loss')
  plt.ylabel('Loss')
  plt.xlabel('Epoch')
  plt.legend(['Train', 'Val'], loc='upper left')
  plt.show()

  # Plot training & validation accuracy values
  plt.plot(train_acc_history)
  plt.plot(val_acc_history)
  plt.title('Model accuracy')
  plt.ylabel('Accuracy')
  plt.xlabel('Epoch')
  plt.legend(['Train', 'Val'], loc='upper left')
  plt.show()

"""Code for defining and training your MLP models"""

def create_mlp(args=None):
	# You can use args to pass parameter values to this method

	# Define model architecture
	model = Sequential()
	model.add(Dense(units=14*14, activation='relu', input_dim=28*28))
	# add more layers...
	model.add(Dense(units=7*7, activation='relu'))
	model.add(Dense(units=10, activation='softmax'))

	# Define Optimizer
	optimizer = keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)

	# Compile
	model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])

	return model

def train_mlp(x_train, y_train, x_vali=None, y_vali=None, args=None):
	# You can use args to pass parameter values to this method
	y_train = keras.utils.to_categorical(y_train, num_classes=None)
	model = create_mlp(args)

	print('Start to fir MLP...')
	history = model.fit(x=x_train, y=y_train, validation_split=0.1, epochs=8)
	return model, history

"""Code for defining and training your CNN models"""

def create_cnn(args=None):
	# You can use args to pass parameter values to this method

	# 28x28 images with 1 color channel
	input_shape = (28, 28, 1)

	# Define model architecture
	model = Sequential()
	model.add(Conv2D(filters=16, activation='relu', kernel_size=3, input_shape=input_shape))

	# can add more layers here...
	model.add(Conv2D(filters=16, activation='relu', kernel_size=3, input_shape=input_shape))
	model.add(MaxPooling2D(pool_size=(2, 2)))
	model.add(Dropout(0.25))

	model.add(Conv2D(filters=32, activation='relu', kernel_size=3))
	model.add(Conv2D(filters=32, activation='relu', kernel_size=3))
	model.add(MaxPooling2D(pool_size=(2, 2)))
	model.add(Dropout(0.25))

	model.add(Flatten())
	# can add more layers here...
	model.add(Dense(units=512, activation='relu'))
	model.add(Dense(units=10, activation='softmax'))

	# Optimizer
	optimizer = keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)

	# Compile
	model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])

	return model


def train_cnn(x_train, y_train, x_vali=None, y_vali=None, args=None):
	# You can use args to pass parameter values to this method
	x_train = x_train.reshape(-1, 28, 28, 1)
	y_train = keras.utils.to_categorical(y_train, num_classes=None)
	model = create_cnn(args)

	val_split = 0.1 if not args or 'val_split' not in args else args['val_split']

	history = model.fit(x=x_train, y=y_train, validation_split=val_split, epochs=8)
	return model, history

"""An optional method you can use to repeatedly call create_mlp, train_mlp, create_cnn, or train_cnn.
You can use it for performing cross validation or parameter searching.
"""

def train_and_select_model(train_csv):
	"""Optional method. You can write code here to perform a
	parameter search, cross-validation, etc. """

	x_train, y_train = get_data(train_csv)

	args = {
		'learning_rate': 0.01,
	}
	model, history = train_mlp(x_train, y_train, x_vali=None, y_vali=None, args=None)
	validation_accuracy = history.history['val_acc']

	return best_model, history

"""Main method. Make sure the file paths here point to the correct place in your google drive."""

if __name__ == '__main__':
  ### Switch to "development_mode = False" before you submit ###
  grading_mode = True
  if grading_mode:
    # When we grade, we'll provide the file names as command-line arguments
    if (len(sys.argv) != 3):
      print("Usage:\n\tpython3 fashion.py train_file test_file")
      exit()

    train_file, test_file = sys.argv[1], sys.argv[2]

    # train_file = '/content/drive/My Drive/fashion_data/fashion_train.csv'
    # test_file = '/content/drive/My Drive/fashion_data/fashion_test.csv'

    # train your best model
    x_train, y_train = get_data(train_file)
    best_model, _ = train_cnn(x_train, y_train, args={'val_split': 0})

    x_test, _ = get_data(test_file)
    x_test = x_test.reshape(-1, 28, 28, 1)

    predictions = best_model.predict(x_test).argmax(1)

    # use your best model to generate predictions for the test_file
    output_predictions(predictions)

  # Include all of the required figures in your report. Don't generate them here.
  else:
    ### Edit the following two lines if your paths are different
    train_file = '/content/drive/My Drive/fashion_data/fashion_train.csv'
    test_file = '/content/drive/My Drive/fashion_data/fashion_test.csv'
    x_train, y_train = get_data(train_file)
    # mlp_model, mlp_history = train_mlp(x_train, y_train)
    cnn_model, cnn_history = train_cnn(x_train, y_train)

    print(cnn_model.summary())
    plot_history(cnn_history)

    # visualize_weights(mlp_model)
